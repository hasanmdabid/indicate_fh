{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clear_folder import clear_folder\n",
    "import logging\n",
    "from split_data import *\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.utils import Sequence\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.utils import Sequence\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "logging.getLogger('tensorflow').disabled = True\n",
    "# Initialize the data generator\n",
    "\n",
    "datapath = '/home/abidhasan/Documents/Indicate_FH/data'\n",
    "train_dir = '/home/abidhasan/Documents/Indicate_FH/train_val_test/train'\n",
    "test_dir = '/home/abidhasan/Documents/Indicate_FH/train_val_test/test'\n",
    "model_dir = '/home/abidhasan/Documents/Indicate_FH/saved_model/'\n",
    "figpath = '/home/abidhasan/Documents/Indicate_FH/performance_figures'\n",
    "checkpointpath = '/home/abidhasan/Documents/Indicate_FH/checkpoints'\n",
    "batch_size = 64\n",
    "size = 224\n",
    "dropout_rt = 0.4\n",
    "image_size = (size, size)\n",
    "n_channels = 3\n",
    "epochs = 100\n",
    "\n",
    "train_data_ratio = 0.8\n",
    "val_data_ratio = 0.0\n",
    "test_data_ratio = 0.2\n",
    "\n",
    "# ModelCheckpoint callback saves a model at some interval.\n",
    "# File name includes epoch and validation accuracy.\n",
    "\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, image_dir, batch_size, image_size, n_channels=3, shuffle=True):\n",
    "        self.image_dir = image_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size\n",
    "        self.n_channels = n_channels\n",
    "        self.shuffle = shuffle\n",
    "        self.supported_formats = ['.jpg', '.jpeg', '.png', '.gif', '.bmp']\n",
    "        self.image_files, self.labels = self._load_image_files()\n",
    "        self.indexes = np.arange(len(self.image_files))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.image_files) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        batch_files = [self.image_files[k] for k in indexes]\n",
    "        batch_labels = [self.labels[k] for k in indexes]\n",
    "\n",
    "        X = np.empty((self.batch_size, *self.image_size,\n",
    "                     self.n_channels), dtype=np.float32)\n",
    "        y = np.empty((self.batch_size), dtype=np.float32)\n",
    "\n",
    "        for i, file in enumerate(batch_files):\n",
    "            image = self.load_image(file)\n",
    "            if image is not None:\n",
    "                X[i,] = image\n",
    "                y[i] = batch_labels[i]\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def _load_image_files(self):\n",
    "        image_files = []\n",
    "        labels = []\n",
    "        for label, category in enumerate(['not_effected', 'effected']):\n",
    "            category_dir = os.path.join(self.image_dir, category)\n",
    "            for file_name in os.listdir(category_dir):\n",
    "                if any(file_name.lower().endswith(ext) for ext in self.supported_formats):\n",
    "                    image_files.append(os.path.join(category_dir, file_name))\n",
    "                    labels.append(label)\n",
    "        return image_files, labels\n",
    "\n",
    "    def load_image(self, image_path):\n",
    "        try:\n",
    "            image = tf.io.read_file(image_path)\n",
    "            image = tf.image.decode_image(image, channels=self.n_channels)\n",
    "            image = tf.image.resize(image, self.image_size)\n",
    "            image = image / 255.0\n",
    "            return image.numpy()\n",
    "        except:\n",
    "            # If the image cannot be decoded, return None\n",
    "            return None\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            combined = list(zip(self.image_files, self.labels))\n",
    "            np.random.shuffle(combined)\n",
    "            self.image_files, self.labels = zip(*combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_folder('/home/abidhasan/Documents/Indicate_FH/train_val_test')\n",
    "split_data(datapath, train_data_ratio, val_data_ratio, test_data_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to count images in each class\n",
    "import os\n",
    "\n",
    "\n",
    "def count_images(directory):\n",
    "    affected_count = len(os.listdir(os.path.join(directory, 'effected')))\n",
    "    not_affected_count = len(os.listdir(\n",
    "        os.path.join(directory, 'not_effected')))\n",
    "    return affected_count, not_affected_count\n",
    "\n",
    "\n",
    "# Count images in train set\n",
    "train_affected_count, train_not_affected_count = count_images(train_dir)\n",
    "\n",
    "# Count images in test set\n",
    "test_affected_count, test_not_affected_count = count_images(test_dir)\n",
    "\n",
    "# Print the counts\n",
    "print(\n",
    "    f'Train set: Affected - {train_affected_count}, Not Affected - {train_not_affected_count}')\n",
    "print(\n",
    "    f'Test set: Affected - {test_affected_count}, Not Affected - {test_not_affected_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG16\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.models import Model\n",
    "\n",
    "# Load the pre-trained VGG16 model\n",
    "vgg16_model = VGG16(weights='imagenet', include_top=False,\n",
    "                   input_shape=(224, 224, 3))\n",
    "# Freeze the initial layers and fine-tune the later layers\n",
    "for layer in vgg16_model.layers[:15]:\n",
    "    layer.trainable = False\n",
    "for layer in vgg16_model.layers[15:]:\n",
    "    layer.trainable = True\n",
    "# Add new classification layers\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(vgg16_model)\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "x = Flatten()(vgg16_model.output)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "output = Dense(1, activation='softmax')(x)\n",
    "# Create the new model\n",
    "model = Model(inputs=vgg16_model.input, outputs=output)\n",
    "# Compile and train the model on the new dataset\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "checckpoint_filepath = checkpointpath + \\\n",
    "    '/weights-improvement-{epoch:02d}-{val_loss:.2f}.hdf5'\n",
    "# Use Mode = max for accuracy and min for loss.\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\n",
    "mc = ModelCheckpoint(checckpoint_filepath, monitor='val_loss',\n",
    "                     mode='min', verbose=1, save_best_only=True)\n",
    "# CSVLogger logs epoch, acc, loss, val_acc, val_loss\n",
    "log_csv = CSVLogger(checkpointpath+'/my_logs.csv', separator=',', append=False)\n",
    "callbacks_list = [mc, es, log_csv]\n",
    "\n",
    "train_gen = DataGenerator(image_dir=train_dir, batch_size=batch_size,\n",
    "                          image_size=image_size, n_channels=n_channels)\n",
    "test_gen = DataGenerator(image_dir=test_dir, batch_size=batch_size,\n",
    "                         image_size=image_size, n_channels=n_channels, shuffle=False)\n",
    "\n",
    "# Train the model in batches\n",
    "steps_per_epoch = len(train_gen)\n",
    "validation_steps = len(test_gen)\n",
    "\n",
    "\n",
    "history = model.fit(train_gen, epochs=epochs, steps_per_epoch=steps_per_epoch,\n",
    "                    validation_data=test_gen, validation_steps=validation_steps)\n",
    "\n",
    "# Save the model weights after training\n",
    "model.save_weights(model_dir+'vgg16_'+f\"{epochs}\"+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Plotting the Model performcaes, train Vs Validation accuracy and train vs Validation Losses.\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "t = f.suptitle('VGG16(with_weight) Performance', fontsize=12)\n",
    "f.subplots_adjust(top=0.85, wspace=0.3)\n",
    "max_epoch = len(history.history['accuracy'])+1\n",
    "epoch_list = list(range(1, max_epoch))\n",
    "ax1.plot(epoch_list, history.history['accuracy'], label='Train Accuracy')\n",
    "ax1.plot(\n",
    "    epoch_list, history.history['val_accuracy'], label='Validation Accuracy')\n",
    "ax1.set_xticks(np.arange(1, max_epoch, 5))\n",
    "ax1.set_ylabel('Accuracy Value')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_title('Accuracy')\n",
    "l1 = ax1.legend(loc=\"best\")\n",
    "\n",
    "\n",
    "ax2.plot(epoch_list, history.history['loss'], label='Train Loss')\n",
    "ax2.plot(epoch_list, history.history['val_loss'], label='Validation Loss')\n",
    "ax2.set_xticks(np.arange(1, max_epoch, 5))\n",
    "ax2.set_ylabel('Loss Value')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_title('Loss')\n",
    "l2 = ax2.legend(loc=\"best\")\n",
    "plt.show()\n",
    "\n",
    "plt.savefig(figpath+'/VGG16_TRAIN_VS_VALIDATION_LOSS_with_weights.png',\n",
    "            bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test data\n",
    "loss, accuracy = model.evaluate(test_gen, steps=len(test_gen))\n",
    "print(f'Test accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Get predictions for the test dataset\n",
    "predictions = model.predict(test_gen, steps=len(test_gen))\n",
    "predicted_classes = (predictions > 0.5).astype(\"int32\")\n",
    "\n",
    "# Print predicted classes\n",
    "print(predicted_classes)\n",
    "\n",
    "# Get true labels and predictions\n",
    "true_labels = []\n",
    "for i in range(len(test_gen)):\n",
    "    _, labels = test_gen[i]\n",
    "    true_labels.extend(labels)\n",
    "\n",
    "true_labels = np.array(true_labels)\n",
    "\n",
    "# Calculate ROC curve and AUC\n",
    "fpr, tpr, thresholds = roc_curve(true_labels, predictions)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2,\n",
    "         label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(true_labels, predicted_classes)\n",
    "\n",
    "# Display the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\n",
    "                              'Not Affected', 'Affected'])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
